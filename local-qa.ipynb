{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e240c-afb4-44cb-9c3c-cbfc9e3d88cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75f281-803e-4e8c-96f9-5d838154a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gpt4all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82024b1a-74be-4543-b009-b3c9ef9f6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade langchain==0.0.353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2462c7-397a-496f-85f6-a7aa8d3a7536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain                     0.0.353\n",
      "langchain-community           0.0.11\n",
      "langchain-core                0.1.9\n",
      "langchainhub                  0.1.14\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90404cbd-a9ad-451c-8696-20043edee5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import langchain_community\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import vectorstores\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.llms import GPT4All\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community import vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ed786de-85fd-475a-b19c-684eb35ed4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_name = '/Users/andkelly/Library/CloudStorage/Dropbox/Applications Folder/Resumes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1808be11-7b91-451a-92d2-ab8045756388",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(path_name, glob=\"**/*.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "433f41d7-81b3-489e-9c58-ac6a5cabd707",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c7cd9a3-7015-4126-b0d7-7329bbe435c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=256, chunk_overlap=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6423d462-738d-4364-a984-f07a49285d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beee3cc0-d7ad-4558-8d06-6a9e7bcd4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = langchain_community.vectorstores.utils.filter_complex_metadata(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91785d1a-4fee-4881-b2b4-e18b4ef4fe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: gguf version     = 2\n",
      "bert_load_from_file: gguf alignment   = 32\n",
      "bert_load_from_file: gguf data offset = 695552\n",
      "bert_load_from_file: model name           = BERT\n",
      "bert_load_from_file: model architecture   = bert\n",
      "bert_load_from_file: model file type      = 1\n",
      "bert_load_from_file: bert tokenizer vocab = 30522\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(documents=texts, embedding=GPT4AllEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c56eb-f3b3-40de-a6c3-32bd68218b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What has Andrew done?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6afd5e-774c-4570-9579-17f35d53e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectorstore.similarity_search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4816555e-976d-4faf-87f4-43abeb77267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f6f525-54d8-4758-b9d8-d44d51b475da",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2557c4c-66f0-4b16-84a9-6b56440309c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GPT4All(\n",
    "    model=\"/Users/andkelly/Applications/models/mistral-7b-openorca.Q4_0.gguf\",\n",
    "    max_tokens=2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d805ea-adde-461e-b503-962f3b2c6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = gpt4all.generate([\"The capital of the United States is...\"], max_tokens=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5938f424-9798-46d8-9228-2e08efc4a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e25f0c-b4f6-478b-af57-45ac51e3e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"Give me Andrew's elevator pitch from these retrieved docs: {docs}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84937335-12b1-4261-aaa6-d702b6d729ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ede76-38df-4ee3-8e3a-59623f20b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a48b3-bc83-4c44-a234-80672126118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = {\"docs\": format_docs} | prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b059a8-e97c-4a9a-907b-e6649e13766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about yourself\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8048aeb4-82d1-4d9b-926b-e51c4833fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "581d739f-42ed-4cc2-810c-b7419e912d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5d39857-ab6e-4477-8121-296b6443142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a24de-8cbf-4ec1-93ae-2556993821a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(rag_prompt.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ed6c3c9-8372-493d-b000-8e08ef4c8574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnablePick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca4f2d-35fd-4b1c-a6ce-76cc6023daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunnablePick(\"context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181214d-7800-4028-b933-33436ada8ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunnablePassthrough.assign(context = RunnablePick(\"context\") | format_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d06ba4-2840-4353-8f9c-9229def3015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunnablePassthrough.assign(context=RunnablePick(\"context\") | format_docs) | rag_prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb293e-7a8d-4db8-8085-b016133e6227",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt[0].prompt.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6dd432-094c-46e9-9eb6-94f14857d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(context=RunnablePick(\"context\") | format_docs)\n",
    "    | rag_prompt[0].prompt.map\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "960c806a-16cb-4c24-810e-b6cafd112f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about yourself\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5efde27-8470-4776-98d3-32e91617f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"context\": docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9b5644f-0854-43e1-870c-161a83bcf25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d5a15cb-ff4e-4799-afe3-13a0042d171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = lambda x: format_docs(x[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35642320-a097-4878-87ac-d60d2f4b802f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f85c3da-f118-40ef-b072-9031e6c4e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_from_docs = (\n",
    "    # {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1687b5b8-5e65-4313-857e-a0c6a0c72aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1605db1d-e653-4db4-b099-b65902f5bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer = rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49b37e56-79c3-41f1-b2f0-f69d0f5227b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain_with_source.invoke(\"What is Andrew's elevator pitch?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "805ddce2-1770-4642-8a90-7488a2a5bad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/andkelly/Library/CloudStorage/Dropbox/Applications Folder/Resumes/2023_Kelly_Andrew_Capital_One_Resume.pdf'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['context'][0].metadata['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdccfb49-c912-4bbf-bff6-056aeac85b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f64fe-19f0-45ae-8dce-984c5ee12cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb82012-31a6-4b7a-a465-5a5c8a36109f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ab263-b4c3-40bb-95ee-7f951c3c8500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cdd3c15-2438-4a31-b323-f034a7877a34",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The input to RunnablePassthrough.assign() must be a dict.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mqa_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langchain_core/runnables/base.py:1774\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 1774\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1777\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langchain_core/runnables/passthrough.py:415\u001b[0m, in \u001b[0;36mRunnableAssign.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28minput\u001b[39m: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    412\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    414\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langchain_core/runnables/base.py:975\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m    972\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[1;32m    973\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m    974\u001b[0m         Output,\n\u001b[0;32m--> 975\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    978\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    979\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    983\u001b[0m     )\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    985\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langchain_core/runnables/config.py:323\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    322\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/langchain_core/runnables/passthrough.py:396\u001b[0m, in \u001b[0;36mRunnableAssign._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke\u001b[39m(\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28minput\u001b[39m: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    395\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mdict\u001b[39m\n\u001b[1;32m    398\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapper\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    406\u001b[0m         ),\n\u001b[1;32m    407\u001b[0m     }\n",
      "\u001b[0;31mAssertionError\u001b[0m: The input to RunnablePassthrough.assign() must be a dict."
     ]
    }
   ],
   "source": [
    "qa_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d3069-7162-4a24-badd-0d126da2a3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05eea17-4109-4c48-bfdb-810362629a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b216e-8168-425b-99b5-d8e7d3fba4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dca83b-3262-49cf-9696-fb09548840dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05a00881-4718-4d40-a81a-d6d81054613f",
   "metadata": {},
   "source": [
    "# Update Q&A Doc Retrieval w/ Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daffa32b-4c2e-4a4e-877a-5ab145770648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_retriever(path_name):\n",
    "    loader = DirectoryLoader(path_name, glob=\"**/*.pdf\")\n",
    "    docs = loader.load()\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=256, chunk_overlap=0\n",
    "    )\n",
    "    texts = text_splitter.split_documents(docs)\n",
    "    texts = langchain_community.vectorstores.utils.filter_complex_metadata(texts)\n",
    "    embeddings = GPT4AllEmbeddings()\n",
    "    vectorstore = Chroma.from_documents(texts, embeddings)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f2451-f177-49fd-997b-b018257553d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(user_input, chat_history, retriever):\n",
    "    llm = GPT4All(\n",
    "        model=\"/Users/andkelly/Applications/models/mistral-7b-openorca.Q4_0.gguf\",\n",
    "        max_tokens=2048\n",
    "    )\n",
    "    \n",
    "    _template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "    \n",
    "\tChat History:\n",
    "\t{chat_history}\n",
    "\tFollow Up Input: {question}\n",
    "\tStandalone question:\"\"\"\n",
    "    \n",
    "    CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "    \n",
    "    question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "    \n",
    "    doc_chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\")\n",
    "    \n",
    "    chain = ConversationalRetrievalChain(\n",
    "        retriever=retriever,\n",
    "        question_generator=question_generator,\n",
    "        combine_docs_chain=doc_chain\n",
    "    )\n",
    "    \n",
    "    result = chain({\"question\": user_input, \"chat_history\": chat_history})\n",
    "    \n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd722c30-23cb-4c95-9357-6404958bc0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CONDENSE_QUESTION_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eacf2e2-7d8d-40a3-b836-ae8b1891affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "\tpath_name = input(\"Enter path name: \")\n",
    "\tretriever = make_retriever(path_name)\n",
    "\tprint(\"Ask a question...\")\n",
    "\tchat_history = []\n",
    "\twhile True:\n",
    "\t\tuser_input = input(\"You: \")\n",
    "\t\tresponse = get_answer(user_input, chat_history, retriever)\n",
    "\t\tchat_history = [(user_input, response)]\n",
    "\t\tprint(\"Response: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644fe3c-ce97-45c7-9c4d-99ccfb788be6",
   "metadata": {},
   "source": [
    "Note: When I use a local model in the previously developed Q&A over docs that cites sources, I was returned an error about instantiating classess for the BasePromptTemplate and BaseLanguageModel. As a result, I'm going to try followiung the turtorial docs [here](https://python.langchain.com/docs/use_cases/question_answering/local_retrieval_qa#using-in-a-chain). If that fails, then I can explore the documentation [here](https://python.langchain.com/docs/use_cases/question_answering/quickstart). Last resort is to reach out to Alex Talbot to see what they did for CDER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0552f0-b655-4f3c-980c-5d28ae4e0825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
